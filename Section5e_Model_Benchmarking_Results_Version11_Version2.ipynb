{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f96b18",
   "metadata": {},
   "source": [
    "# Section V.E. Model Benchmarking Results\n",
    "\n",
    "This notebook benchmarks ARIMA, Prophet, LSTM, Random Forest, and XGBoost for time series forecasting of the simulated workload metrics in `SimulatedQueryMetrics.csv`.\n",
    "\n",
    "> **Note:** For brevity and reproducibility, this example uses simple versions and default parameters. For robust benchmarks, perform hyperparameter tuning and use a robust cross-validation scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270a899",
   "metadata": {},
   "source": [
    "## 1. Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de2f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "\n",
    "# For LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('SimulatedQueryMetrics.csv', parse_dates=['MetricDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16344c",
   "metadata": {},
   "source": [
    "## 2. Prepare Data Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a78051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(df, query, variant, metric):\n",
    "    s = df[(df['QueryName']==query) & (df['QueryVariant']==variant)].sort_values('MetricDate')[['MetricDate', metric]].copy()\n",
    "    s = s.rename(columns={'MetricDate':'ds', metric:'y'})\n",
    "    s['y'] = s['y'].interpolate().fillna(method='bfill')\n",
    "    return s\n",
    "\n",
    "# For supervised learning (tabular) models\n",
    "def make_supervised(series, n_lags=5):\n",
    "    df = pd.DataFrame(series)\n",
    "    for i in range(1, n_lags+1):\n",
    "        df[f'lag_{i}'] = df['y'].shift(i)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    X = df[[f'lag_{i}' for i in range(1, n_lags+1)]].values\n",
    "    y = df['y'].values\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3daf2",
   "metadata": {},
   "source": [
    "## 3. Benchmarking Loop (One Query and Variant Example)\n",
    "You can expand this for all queries/variants and metrics in a full run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3b770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:36:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:36:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:36:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:36:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:37:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:37:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B8EC913A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B8EC913A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:37:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:37:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:37:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:37:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:37:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:37:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "metrics = ['CPU', 'LatencyMs', 'LogicalReads']\n",
    "queries = ['Q1', 'Q2']\n",
    "variant = 1  # Example: use variant 1 for brevity\n",
    "n_test = 48  # Last 2 days as test\n",
    "\n",
    "for query in queries:\n",
    "    for metric in metrics:\n",
    "        s = get_series(df, query, variant, metric)\n",
    "        train, test = s.iloc[:-n_test], s.iloc[-n_test:]\n",
    "\n",
    "        # ARIMA\n",
    "        try:\n",
    "            arima = ARIMA(train['y'], order=(2,1,2)).fit()\n",
    "            pred_arima = arima.forecast(steps=n_test)\n",
    "            rmse_arima = np.sqrt(mean_squared_error(test['y'], pred_arima))\n",
    "        except:\n",
    "            rmse_arima = np.nan\n",
    "\n",
    "        # Prophet\n",
    "        try:\n",
    "            m = Prophet()\n",
    "            m.fit(train)\n",
    "            forecast = m.predict(test[['ds']])\n",
    "            pred_prophet = forecast['yhat'].values\n",
    "            rmse_prophet = np.sqrt(mean_squared_error(test['y'], pred_prophet))\n",
    "        except:\n",
    "            rmse_prophet = np.nan\n",
    "\n",
    "        # LSTM (robust, corrected version)\n",
    "        try:\n",
    "            scaler = StandardScaler()\n",
    "            all_data = np.concatenate([train['y'].values, test['y'].values])\n",
    "            all_scaled = scaler.fit_transform(all_data.reshape(-1, 1)).flatten()\n",
    "            train_scaled = all_scaled[:len(train)]\n",
    "            test_scaled = all_scaled[len(train)-5:]  # Include last 5 train for windowing\n",
    "\n",
    "            # Create lagged sequences\n",
    "            def create_lstm_data(series, n_lags=5):\n",
    "                X, y = [], []\n",
    "                for i in range(n_lags, len(series)):\n",
    "                    X.append(series[i-n_lags:i])\n",
    "                    y.append(series[i])\n",
    "                X = np.array(X)\n",
    "                y = np.array(y)\n",
    "                return X[..., np.newaxis], y\n",
    "\n",
    "            X_train, y_train = create_lstm_data(train_scaled, n_lags=5)\n",
    "            X_test, y_test = create_lstm_data(test_scaled, n_lags=5)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(16, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mse', optimizer='adam')\n",
    "            model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=0)\n",
    "\n",
    "            pred_lstm_scaled = model.predict(X_test)\n",
    "            # Inverse transform\n",
    "            pred_lstm = scaler.inverse_transform(pred_lstm_scaled)\n",
    "            y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "            rmse_lstm = np.sqrt(mean_squared_error(y_test_inv, pred_lstm))\n",
    "        except Exception as e:\n",
    "            print(f'LSTM error for {query}-{metric}:', e)\n",
    "            rmse_lstm = np.nan\n",
    "\n",
    "        # Random Forest\n",
    "        try:\n",
    "            X_train, y_train = make_supervised(train['y'], n_lags=5)\n",
    "            X_test, y_test = make_supervised(pd.concat([train['y'][-5:], test['y']]), n_lags=5)\n",
    "            rf = RandomForestRegressor(n_estimators=50)\n",
    "            rf.fit(X_train, y_train)\n",
    "            pred_rf = rf.predict(X_test)\n",
    "            rmse_rf = np.sqrt(mean_squared_error(y_test, pred_rf))\n",
    "        except:\n",
    "            rmse_rf = np.nan\n",
    "\n",
    "        # XGBoost\n",
    "        try:\n",
    "            xgb = XGBRegressor(n_estimators=50)\n",
    "            xgb.fit(X_train, y_train)\n",
    "            pred_xgb = xgb.predict(X_test)\n",
    "            rmse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
    "        except:\n",
    "            rmse_xgb = np.nan\n",
    "\n",
    "        results.append({\n",
    "            'Query': query,\n",
    "            'Metric': metric,\n",
    "            'ARIMA': rmse_arima,\n",
    "            'Prophet': rmse_prophet,\n",
    "            'LSTM': rmse_lstm,\n",
    "            'RandomForest': rmse_rf,\n",
    "            'XGBoost': rmse_xgb\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188ba40",
   "metadata": {},
   "source": [
    "## 4. Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ad9045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Metric</th>\n",
       "      <th>ARIMA</th>\n",
       "      <th>Prophet</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>CPU</td>\n",
       "      <td>10.05</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>LatencyMs</td>\n",
       "      <td>19.95</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>LogicalReads</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.49</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2</td>\n",
       "      <td>CPU</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2</td>\n",
       "      <td>LatencyMs</td>\n",
       "      <td>19.16</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q2</td>\n",
       "      <td>LogicalReads</td>\n",
       "      <td>12.43</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Query        Metric  ARIMA  Prophet  LSTM  RandomForest  XGBoost\n",
       "0    Q1           CPU  10.05     1.61  2.72          2.80     2.72\n",
       "1    Q1     LatencyMs  19.95     4.50  4.73          4.83     4.75\n",
       "2    Q1  LogicalReads  14.00     2.03  3.49          3.85     3.79\n",
       "3    Q2           CPU  10.32     1.68  3.06          2.88     3.08\n",
       "4    Q2     LatencyMs  19.16     4.07  4.90          5.08     4.84\n",
       "5    Q2  LogicalReads  12.43     2.14  3.46          3.33     3.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results)\n",
    "display(res_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d2b2e",
   "metadata": {},
   "source": [
    "- The table shows RMSE for each model, metric, and query (lower is better).\n",
    "- Highlight the best (lowest) RMSE in each row for reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b78c1e",
   "metadata": {},
   "source": [
    "## Troubleshooting LSTM NaN Values\n",
    "\n",
    "- If you observe NaN for LSTM RMSE, this usually arises from a shape mismatch, insufficient test samples for windowing, or improper scaling/inverse-scaling.\n",
    "- The above LSTM code ensures:\n",
    "    - Correct handling of test windowing (includes previous lags from train).\n",
    "    - Consistent scaling/inverse-scaling for both train and test set.\n",
    "    - No missing values are present in LSTM input windows.\n",
    "- If you still encounter NaN, check for data leakage, extreme outliers, or try increasing the test set size or epochs for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56123d",
   "metadata": {},
   "source": [
    "## 5. Interpretation\n",
    "- Prophet often achieves the lowest RMSE, indicating superior handling of trend/seasonality.\n",
    "- Tree-based models (RF/XGBoost) may outperform ARIMA/LSTM, but generally not Prophet.\n",
    "- LSTM performance may be limited by dataset size and strong deterministic structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
