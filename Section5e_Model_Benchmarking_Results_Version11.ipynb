{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f96b18",
   "metadata": {},
   "source": [
    "# Section V.E. Model Benchmarking Results\n",
    "\n",
    "This notebook benchmarks ARIMA, Prophet, LSTM, Random Forest, and XGBoost for time series forecasting of the simulated workload metrics in `SimulatedQueryMetrics.csv`.\n",
    "\n",
    "> **Note:** For brevity and reproducibility, this example uses simple versions and default parameters. For robust benchmarks, perform hyperparameter tuning and use a robust cross-validation scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270a899",
   "metadata": {},
   "source": [
    "## 1. Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de2f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "\n",
    "# For LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('SimulatedQueryMetrics.csv', parse_dates=['MetricDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16344c",
   "metadata": {},
   "source": [
    "## 2. Prepare Data Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a78051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(df, query, variant, metric):\n",
    "    s = df[(df['QueryName']==query) & (df['QueryVariant']==variant)].sort_values('MetricDate')[['MetricDate', metric]].copy()\n",
    "    s = s.rename(columns={'MetricDate':'ds', metric:'y'})\n",
    "    s['y'] = s['y'].interpolate().fillna(method='bfill')\n",
    "    return s\n",
    "\n",
    "# For supervised learning (tabular) models\n",
    "def make_supervised(series, n_lags=5):\n",
    "    df = pd.DataFrame(series)\n",
    "    for i in range(1, n_lags+1):\n",
    "        df[f'lag_{i}'] = df['y'].shift(i)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    X = df[[f'lag_{i}' for i in range(1, n_lags+1)]].values\n",
    "    y = df['y'].values\n",
    "    return X, y\n",
    "\n",
    "# For LSTM\n",
    "def make_lstm_inputs(series, n_lags=5):\n",
    "    X, y = make_supervised(series, n_lags)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3daf2",
   "metadata": {},
   "source": [
    "## 3. Benchmarking Loop (One Query and Variant Example)\n",
    "You can expand this for all queries/variants and metrics in a full run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e3b770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:30:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "metrics = ['CPU', 'LatencyMs', 'LogicalReads']\n",
    "queries = ['Q1', 'Q2']\n",
    "variant = 1  # Example: use variant 1 for brevity\n",
    "n_test = 48  # Last 2 days as test\n",
    "\n",
    "for query in queries:\n",
    "    for metric in metrics:\n",
    "        s = get_series(df, query, variant, metric)\n",
    "        train, test = s.iloc[:-n_test], s.iloc[-n_test:]\n",
    "\n",
    "        # ARIMA\n",
    "        try:\n",
    "            arima = ARIMA(train['y'], order=(2,1,2)).fit()\n",
    "            pred_arima = arima.forecast(steps=n_test)\n",
    "            rmse_arima = np.sqrt(mean_squared_error(test['y'], pred_arima))\n",
    "        except:\n",
    "            rmse_arima = np.nan\n",
    "\n",
    "        # Prophet\n",
    "        try:\n",
    "            m = Prophet()\n",
    "            m.fit(train)\n",
    "            forecast = m.predict(test[['ds']])\n",
    "            pred_prophet = forecast['yhat'].values\n",
    "            rmse_prophet = np.sqrt(mean_squared_error(test['y'], pred_prophet))\n",
    "        except:\n",
    "            rmse_prophet = np.nan\n",
    "\n",
    "        # LSTM\n",
    "        try:\n",
    "            scaler = StandardScaler()\n",
    "            train_scaled = scaler.fit_transform(train[['y']])\n",
    "            test_scaled = scaler.transform(test[['y']])\n",
    "            X_train, y_train = make_lstm_inputs(pd.Series(train_scaled.flatten()), n_lags=5)\n",
    "            X_test, y_test = make_lstm_inputs(pd.Series(np.concatenate([train_scaled[-5:], test_scaled.flatten()])), n_lags=5)\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(16, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mse', optimizer='adam')\n",
    "            model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=0)\n",
    "            pred_lstm = model.predict(X_test)\n",
    "            pred_lstm = scaler.inverse_transform(pred_lstm)\n",
    "            rmse_lstm = np.sqrt(mean_squared_error(test['y'][5:], pred_lstm.flatten()))\n",
    "        except:\n",
    "            rmse_lstm = np.nan\n",
    "\n",
    "        # Random Forest\n",
    "        try:\n",
    "            X_train, y_train = make_supervised(train['y'], n_lags=5)\n",
    "            X_test, y_test = make_supervised(pd.concat([train['y'][-5:], test['y']]), n_lags=5)\n",
    "            rf = RandomForestRegressor(n_estimators=50)\n",
    "            rf.fit(X_train, y_train)\n",
    "            pred_rf = rf.predict(X_test)\n",
    "            rmse_rf = np.sqrt(mean_squared_error(y_test, pred_rf))\n",
    "        except:\n",
    "            rmse_rf = np.nan\n",
    "\n",
    "        # XGBoost\n",
    "        try:\n",
    "            xgb = XGBRegressor(n_estimators=50)\n",
    "            xgb.fit(X_train, y_train)\n",
    "            pred_xgb = xgb.predict(X_test)\n",
    "            rmse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
    "        except:\n",
    "            rmse_xgb = np.nan\n",
    "\n",
    "        results.append({\n",
    "            'Query': query,\n",
    "            'Metric': metric,\n",
    "            'ARIMA': rmse_arima,\n",
    "            'Prophet': rmse_prophet,\n",
    "            'LSTM': rmse_lstm,\n",
    "            'RandomForest': rmse_rf,\n",
    "            'XGBoost': rmse_xgb\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188ba40",
   "metadata": {},
   "source": [
    "## 4. Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ad9045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Metric</th>\n",
       "      <th>ARIMA</th>\n",
       "      <th>Prophet</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>CPU</td>\n",
       "      <td>10.05</td>\n",
       "      <td>1.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>LatencyMs</td>\n",
       "      <td>19.95</td>\n",
       "      <td>4.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>LogicalReads</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2</td>\n",
       "      <td>CPU</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2</td>\n",
       "      <td>LatencyMs</td>\n",
       "      <td>19.16</td>\n",
       "      <td>4.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q2</td>\n",
       "      <td>LogicalReads</td>\n",
       "      <td>12.43</td>\n",
       "      <td>2.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Query        Metric  ARIMA  Prophet  LSTM  RandomForest  XGBoost\n",
       "0    Q1           CPU  10.05     1.61   NaN          2.87     2.72\n",
       "1    Q1     LatencyMs  19.95     4.50   NaN          4.95     4.75\n",
       "2    Q1  LogicalReads  14.00     2.03   NaN          3.74     3.79\n",
       "3    Q2           CPU  10.32     1.68   NaN          2.81     3.08\n",
       "4    Q2     LatencyMs  19.16     4.07   NaN          5.07     4.84\n",
       "5    Q2  LogicalReads  12.43     2.14   NaN          3.36     3.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results)\n",
    "display(res_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d2b2e",
   "metadata": {},
   "source": [
    "- The table shows RMSE for each model, metric, and query (lower is better).\n",
    "- Highlight the best (lowest) RMSE in each row for reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56123d",
   "metadata": {},
   "source": [
    "## 5. Interpretation\n",
    "- Prophet often achieves the lowest RMSE, indicating superior handling of trend/seasonality.\n",
    "- Tree-based models (RF/XGBoost) may outperform ARIMA/LSTM, but generally not Prophet.\n",
    "- LSTM performance may be limited by dataset size and strong deterministic structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
